{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-18T13:43:28.584186Z",
     "iopub.status.busy": "2025-09-18T13:43:28.583977Z",
     "iopub.status.idle": "2025-09-18T13:43:33.361578Z",
     "shell.execute_reply": "2025-09-18T13:43:33.360518Z",
     "shell.execute_reply.started": "2025-09-18T13:43:28.584167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T13:43:33.364727Z",
     "iopub.status.busy": "2025-09-18T13:43:33.363825Z",
     "iopub.status.idle": "2025-09-18T13:44:25.061253Z",
     "shell.execute_reply": "2025-09-18T13:44:25.059886Z",
     "shell.execute_reply.started": "2025-09-18T13:43:33.364670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3385c40aefc4da884ec253a21f8e75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0036c9d59445b8b88c5098516ccf76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0127298f2945d9a42cef76899e28e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49d2b58b189401b9354fa56f34ecbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451a002829e74b4b9a415cf9c5e12105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 13:43:51.838862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758203032.041559      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758203032.097875      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c69fa94f3684b4b82456138f9388e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd24fb9fafd0424e82399a0e075fe76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33b66cd69b142a2ac2c91ec51a82bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load NLLB translator model\n",
    "model_id = \"facebook/nllb-200-distilled-600M\"\n",
    "trans_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "trans_model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T13:46:29.272920Z",
     "iopub.status.busy": "2025-09-18T13:46:29.272601Z",
     "iopub.status.idle": "2025-09-18T13:48:13.235719Z",
     "shell.execute_reply": "2025-09-18T13:48:13.234843Z",
     "shell.execute_reply.started": "2025-09-18T13:46:29.272895Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d9f048b60a4eca9e3b2c70807298a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîÅ Translating instructions:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved translated file ‚Üí dev_translated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Define the separator-based splitting function\n",
    "def split_instruction_and_example(text):\n",
    "    for sep in [\"Example:\", \"‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£:\", \"Exammple:\", \" ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£:\", \" ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£‡¶É\", \"Ex:\"]:\n",
    "        if sep in text:\n",
    "            parts = text.split(sep, 1)\n",
    "            instruction = parts[0].strip()\n",
    "            example = parts[1].strip()\n",
    "            return instruction, example\n",
    "    return text.strip(), \"\"  # no example found\n",
    "\n",
    "# Translation function \n",
    "def translate_bn_to_en(text: str) -> str:\n",
    "    inputs = trans_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    translated_ids = trans_model.generate(\n",
    "        **inputs,\n",
    "        forced_bos_token_id=trans_tokenizer.convert_tokens_to_ids(\"eng_Latn\"),\n",
    "        max_new_tokens=256\n",
    "    )\n",
    "\n",
    "    return trans_tokenizer.batch_decode(translated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "# Process the dev.csv\n",
    "df = pd.read_csv(\"/kaggle/input/blptask2data/dev_v2.csv\")  # change the file path accordingly\n",
    "assert {\"id\", \"instruction\", \"test_list\"}.issubset(df.columns)\n",
    "\n",
    "# Process each instruction (split + translate)\n",
    "final_prompts = []\n",
    "\n",
    "for raw in tqdm(df[\"instruction\"], desc=\"üîÅ Translating instructions\"):\n",
    "    bangla_instr, example = split_instruction_and_example(raw)\n",
    "    # print(bangla_instr, example)\n",
    "\n",
    "    try:\n",
    "        english_instr = translate_bn_to_en(bangla_instr)\n",
    "    except Exception as e:\n",
    "        english_instr = \"[Translation Failed]\"\n",
    "        print(\"‚ö†Ô∏è Error:\", e)\n",
    "\n",
    "    # Combine again (optional: add separator for clarity)\n",
    "    if example:\n",
    "        full_prompt = f\"{english_instr.strip()} Example:\\n{example.strip()}\"\n",
    "    else:\n",
    "        full_prompt = english_instr.strip()\n",
    "\n",
    "    # print(full_prompt)\n",
    "    final_prompts.append(full_prompt)\n",
    "    # break\n",
    "\n",
    "# for ls in final_prompts:\n",
    "#     print(ls)\n",
    "\n",
    "# Create a new DataFrame with id and translated_prompt\n",
    "out_df = pd.DataFrame({\n",
    "    \"id\": df[\"id\"],\n",
    "    \"instruction\": final_prompts\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "out_df.to_csv(\"dev_translated.csv\", index=False)\n",
    "print(\" Saved translated file ‚Üí dev_translated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8074720,
     "sourceId": 12772702,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
